from pyspark import SparkContext
from pyspark.sql import SQLContext

partsupp = sqlContext.read.parquet("hdfs://namenode:8020/mahdi-parquet-data/partsupp.parquet")

partsupp.write.mode('overwrite').format("com.databricks.spark.avro").save("hdfs://namenode:8020/mahdi-avro-data/partsupp.avro")

partsupp = spark.read.format("com.databricks.spark.avro").load("hdfs://namenode:8020/mahdi-avro-data/partsupp.avro")