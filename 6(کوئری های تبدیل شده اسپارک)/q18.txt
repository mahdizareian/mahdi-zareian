from decimal import *
from pyspark.sql.types import *
from pyspark.sql import functions as F
from pyspark.sql import *

customer = sqlContext.read.parquet("hdfs://namenode:8020/mahdi-parquet-data/customer.parquet")
lineitem = sqlContext.read.parquet("hdfs://namenode:8020/mahdi-parquet-data/lineitem.parquet")
orders = sqlContext.read.parquet("hdfs://namenode:8020/mahdi-parquet-data/orders.parquet")

selin = lineitem.groupBy(lineitem.L_ORDERKEY)\
.agg(F.sum(lineitem.L_QUANTITY).alias("SUMQU"))\
.filter(SUMQU > 14)\
.select(lineitem.L_ORDERKEY.alias("LINEKEY"),SUMQU )

selin2 = join(orders,selin.LINEKEY == orders.O_ORDERKEY)\
.join(lineitem,selin.LINEKEY == lineitem.L_ORDERKEY )
 
query18 = join(customer, selin2.O_CUSTKEY == customer.C_CUSTKEY )\
.select(lineitem.L_QUANTITY , customer.C_NAME , customer.C_CUSTKEY , orders.O_ORDERKEY , orders.O_ORDERDATE ,orders.O_TOTALPRICE )\
.groupBy(customer.C_NAME , customer.C_CUSTKEY , orders.O_ORDERKEY , orders.O_ORDERDATE ,orders.O_TOTALPRICE)\
.agg(F.sum(lineitem.L_QUANTITY))\
.orderBy(orders.O_TOTALPRICE , orders.O_ORDERDATE)

query18.limit(100).show()


..................................................................................








************************** having :
otherwise(value)[source]
Evaluates a list of conditions and returns one of multiple possible result expressions. If Column.otherwise() is not invoked, None is returned for unmatched conditions.

See pyspark.sql.functions.when() for example usage.

Parameters:	value â€“ a literal value, or a Column expression.
>>> from pyspark.sql import functions as F
>>> df.select(df.name, F.when(df.age > 3, 1).otherwise(0)).show()
+-----+-------------------------------------+
| name|CASE WHEN (age > 3) THEN 1 ELSE 0 END|
+-----+-------------------------------------+
|Alice|                                    0|
|  Bob|                                    1|
