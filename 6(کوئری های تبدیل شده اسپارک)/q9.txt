from decimal import *
from pyspark.sql.types import *
from pyspark.sql import functions as F
from pyspark.sql import *

nation = sqlContext.read.parquet("hdfs://namenode:8020/mahdi-parquet-data/nation.parquet")
lineitem = sqlContext.read.parquet("hdfs://namenode:8020/mahdi-parquet-data/lineitem.parquet")
orders = sqlContext.read.parquet("hdfs://namenode:8020/mahdi-parquet-data/orders.parquet")
supplier = sqlContext.read.parquet("hdfs://namenode:8020/mahdi-parquet-data/supplier.parquet")
part = sqlContext.read.parquet("hdfs://namenode:8020/mahdi-parquet-data/part.parquet")
partsupp = sqlContext.read.parquet("hdfs://namenode:8020/mahdi-parquet-data/partsupp.parquet")

func1 = lambda a , b , c , d : a * (1 - b ) - c * d

Year = lambda x : x[0: 4]

profit = part.filter(part.P_NAME.like('%hot%'))\
.join(supplier, lineitem.L_SUPPKEY == supplier.S_SUPPKEY)\
.join(partsupp, lineitem.L_SUPPKEY == partsupp.PS_SUPPKEY)\
.join(partsupp, lineitem.L_PARTKEY == partsupp.PS_PARTKEY)\
.join(part, lineitem.L_PARTKEY == part.P_PARTKEY)\
.join(orders, lineitem.L_ORDERKEY == orders.O_ORDERKEY)\
.join(supplier, nation.N_NATIONKEY == supplier.S_NATIONKEY)\
.select( (nation.N_NAME).alias("nation") ,                    Year(ordes.O_ORDERDATE).alias("o_year") , func1 (lineitem.L_EXTENDEDPRICE , lineitem.L_DISCOUNT , partsupp.PS_SUPPLYCOST , lineitem.L_QUANTITY).alias("amount"))

query9 = profit.select ( profit.nation , profit.o_year , profit.agg(F.sum("amount").alias("sum_profit")))\
.groupBY(profit.nation , profit.o_year)\
.orderBy(profit.nation , profit.o_year )







